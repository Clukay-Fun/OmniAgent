"""
æè¿°: æ¡ˆä»¶æŸ¥è¯¢æŠ€èƒ½
ä¸»è¦åŠŸèƒ½:
    - å¤šç»´è¡¨æ ¼æ¡ˆä»¶æŸ¥è¯¢
    - é£ä¹¦æ–‡æ¡£å†…å®¹æœç´¢
    - æ ¼å¼åŒ–æŸ¥è¯¢ç»“æœå¹¶æ„å»ºæ¶ˆæ¯å¡ç‰‡
"""

from __future__ import annotations

import logging
import random
import re
from datetime import date, timedelta
from pathlib import Path
from typing import Any

import yaml

from src.core.skills.base import BaseSkill
from src.core.skills.multi_table_linker import MultiTableLinker
from src.core.types import SkillContext, SkillResult
from src.utils.time_parser import parse_time_range

logger = logging.getLogger(__name__)


# region æ¡ˆä»¶æŸ¥è¯¢æŠ€èƒ½
class QuerySkill(BaseSkill):
    """
    æ¡ˆä»¶æŸ¥è¯¢æŠ€èƒ½

    åŠŸèƒ½:
        - è¯†åˆ«æŸ¥è¯¢æ„å›¾ï¼ˆè¡¨æ ¼/æ–‡æ¡£ï¼‰
        - æå–å…³é”®è¯å’Œæ—¶é—´èŒƒå›´
        - è°ƒç”¨å¯¹åº” MCP å·¥å…·è·å–æ•°æ®
    """
    
    name: str = "QuerySkill"
    description: str = "æŸ¥è¯¢æ¡ˆä»¶ã€å¼€åº­ã€å½“äº‹äººç­‰ä¿¡æ¯"

    def __init__(
        self,
        mcp_client: Any,
        settings: Any = None,
        llm_client: Any = None,
        skills_config: dict[str, Any] | None = None,
    ) -> None:
        """
        åˆå§‹åŒ–æŸ¥è¯¢æŠ€èƒ½

        å‚æ•°:
            mcp_client: MCP å®¢æˆ·ç«¯å®ä¾‹
            settings: é…ç½®ä¿¡æ¯
        """
        self._mcp = mcp_client
        self._settings = settings
        self._llm = llm_client
        self._skills_config = skills_config or {}
        self._linker = MultiTableLinker(mcp_client, skills_config=self._skills_config)

        self._table_aliases = self._skills_config.get("table_aliases", {}) or {}
        self._alias_lookup = self._build_alias_lookup(self._table_aliases)
        self._table_recognition = self._skills_config.get("table_recognition", {}) or {}
        self._confidence_threshold = float(
            self._table_recognition.get("confidence_threshold", 0.65)
        )
        self._auto_confirm_threshold = float(
            self._table_recognition.get("auto_confirm_threshold", 0.85)
        )
        self._max_candidates = int(self._table_recognition.get("max_candidates", 3))

        # ============================================
        # region åŠ è½½å›å¤æ¨¡æ¿éšæœºæ± 
        # ============================================
        self._response_pool = self._load_response_pool()
        # endregion
        # ============================================

        # ç»“æœæ ¼å¼åŒ–å­—æ®µé…ç½®ï¼ˆæ”¯æŒè‡ªå®šä¹‰ï¼‰
        query_cfg = self._skills_config.get("query", {})
        if not query_cfg:
            query_cfg = self._skills_config.get("skills", {}).get("query", {})
        self._query_cfg = query_cfg
        self._display_fields = query_cfg.get("display_fields", {
            "title_left": "å§”æ‰˜äººåŠè”ç³»æ–¹å¼",
            "title_right": "å¯¹æ–¹å½“äº‹äºº",
            "title_suffix": "æ¡ˆç”±",
            "case_no": "æ¡ˆå·",
            "court": "å®¡ç†æ³•é™¢",
            "stage": "ç¨‹åºé˜¶æ®µ",
        })
        self._keyword_fields = query_cfg.get(
            "keyword_fields",
            [
                "å§”æ‰˜äºº",
                "å¯¹æ–¹å½“äº‹äºº",
                "æ¡ˆä»¶åˆ†ç±»",
                "æ¡ˆä»¶çŠ¶æ€",
                "æ¡ˆç”±",
                "æ¡ˆå·",
                "é¡¹ç›®ID",
                "é¡¹ç›®ç±»å‹",
                "å®¡ç†æ³•é™¢",
                "ä¸»åŠå¾‹å¸ˆ",
                "ååŠå¾‹å¸ˆ",
                "è¿›å±•",
                "å¤‡æ³¨",
            ],
        )
        self._all_cases_keywords = query_cfg.get(
            "all_cases_keywords",
            [
                "æ‰€æœ‰æ¡ˆä»¶",
                "å…¨éƒ¨æ¡ˆä»¶",
                "æ¡ˆä»¶åˆ—è¡¨",
                "åˆ—å‡ºæ¡ˆä»¶",
                "æ‰€æœ‰é¡¹ç›®",
                "å…¨éƒ¨é¡¹ç›®",
                "æ‰€æœ‰æ¡ˆå­",
                "å…¨éƒ¨æ¡ˆå­",
                "æŸ¥å…¨éƒ¨",
            ],
        )
        self._keep_view_keywords = query_cfg.get(
            "keep_view_keywords",
            ["æŒ‰è§†å›¾", "å½“å‰è§†å›¾", "ä»…è§†å›¾", "è§†å›¾å†…", "åªçœ‹è§†å›¾"],
        )
        self._all_cases_ignore_default_view = bool(
            query_cfg.get("all_cases_ignore_default_view", True)
        )

    async def execute(self, context: SkillContext) -> SkillResult:
        """
        æ‰§è¡ŒæŸ¥è¯¢é€»è¾‘

        å‚æ•°:
            context: æŠ€èƒ½ä¸Šä¸‹æ–‡

        è¿”å›:
            æŸ¥è¯¢ç»“æœï¼ˆæ–‡æœ¬æˆ–å¡ç‰‡ï¼‰
        """
        query = context.query.strip()
        extra = context.extra or {}

        if self._is_refresh_command(query):
            return await self._refresh_tables()

        target = self._select_target(query)
        if target == "doc":
            params = self._build_doc_params(query)
            try:
                result = await self._mcp.call_tool("feishu.v1.doc.search", params)
                documents = result.get("documents", [])
                if not documents:
                    return self._empty_result("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")
                return self._format_doc_result(documents)
            except Exception as e:
                logger.error("QuerySkill execution error: %s", e)
                return SkillResult(
                    success=False,
                    skill_name=self.name,
                    message=str(e),
                    reply_text="æŸ¥è¯¢å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                )

        pending = self._get_pending_table(context)
        if pending:
            resolved = self._resolve_pending_response(query, pending)
            if resolved:
                query = pending.get("query") or query
                extra = dict(extra)
                extra["table_name"] = resolved["table_name"]
                extra["table_id"] = resolved.get("table_id")

        table_result = await self._resolve_table(query, extra)
        if table_result.get("status") == "need_confirm":
            return SkillResult(
                success=True,
                skill_name=self.name,
                data={"pending_table": table_result.get("pending_table")},
                message="éœ€è¦ç¡®è®¤è¡¨å",
                reply_text=table_result.get("reply_text", ""),
            )
        if table_result.get("status") != "resolved":
            return SkillResult(
                success=False,
                skill_name=self.name,
                message=table_result.get("message", "æ— æ³•è¯†åˆ«è¡¨"),
                reply_text=table_result.get("reply_text", "æ— æ³•è¯†åˆ«è¦æŸ¥è¯¢çš„è¡¨ï¼Œè¯·æ˜ç¡®è¡¨åã€‚"),
            )

        tool_name, params = self._build_bitable_params(query, extra, table_result)
        override = self._linker.resolve_query_override(
            query=query,
            current_tool=tool_name,
            params=params,
            target_table_id=table_result.get("table_id"),
            target_table_name=table_result.get("table_name"),
            active_table_id=extra.get("active_table_id"),
            active_table_name=extra.get("active_table_name"),
            active_record=extra.get("active_record") if isinstance(extra.get("active_record"), dict) else None,
        )
        notice = table_result.get("notice")
        if override:
            tool_name, params = override
            if not notice:
                notice = "å·²æŒ‰å½“å‰æ¡ˆä»¶ä¸Šä¸‹æ–‡è”åŠ¨æŸ¥è¯¢å…³è”è¡¨ã€‚"

        try:
            logger.info("Query tool selected: %s, params: %s", tool_name, params)
            result = await self._mcp.call_tool(tool_name, params)
            records = result.get("records", [])
            schema = result.get("schema")
            has_more = bool(result.get("has_more", False))
            page_token = result.get("page_token") or ""
            total = result.get("total")

            relevance_keyword = self._extract_entity_keyword(query)
            if not relevance_keyword:
                relevance_keyword = str(params.get("keyword") or "").strip()
            if relevance_keyword and isinstance(records, list) and len(records) > 1:
                records = self._apply_keyword_relevance(records, relevance_keyword)
                total = len(records)

            pagination_extra = extra.get("pagination") if isinstance(extra.get("pagination"), dict) else None
            current_page = int(pagination_extra.get("current_page") or 0) + 1 if pagination_extra else 1
            query_meta = {
                "tool": tool_name,
                "params": {k: v for k, v in params.items() if k != "page_token"},
            }

            if not records:
                if pagination_extra:
                    return SkillResult(
                        success=True,
                        skill_name=self.name,
                        data={
                            "records": [],
                            "total": total or 0,
                            "schema": schema or [],
                            "pagination": {
                                "has_more": False,
                                "page_token": "",
                                "current_page": current_page,
                                "total": total or 0,
                            },
                            "query_meta": query_meta,
                        },
                        message="æ²¡æœ‰æ›´å¤šè®°å½•",
                        reply_text="å·²ç»æ²¡æœ‰æ›´å¤šè®°å½•äº†ã€‚",
                    )
                if tool_name == "feishu.v1.bitable.search_date_range":
                    field = str(params.get("field") or "").strip()
                    if field == "å¼€åº­æ—¥":
                        return self._empty_result("è¯¥æ—¶é—´èŒƒå›´å†…æ²¡æœ‰å¼€åº­å®‰æ’", prefer_message=True)
                    return self._empty_result("è¯¥æ—¶é—´èŒƒå›´å†…æ²¡æœ‰åŒ¹é…è®°å½•", prefer_message=True)
                return self._empty_result("æœªæ‰¾åˆ°ç›¸å…³æ¡ˆä»¶è®°å½•")
            return self._format_case_result(
                records,
                notice=notice,
                schema=schema,
                pagination={
                    "has_more": has_more,
                    "page_token": page_token,
                    "current_page": current_page,
                    "total": total,
                },
                query_meta=query_meta,
            )
        except Exception as e:
            if tool_name == "feishu.v1.bitable.search_exact" and (
                "Field not found" in str(e) or "InvalidFilter" in str(e)
            ):
                try:
                    fallback_params: dict[str, Any] = {}
                    if params.get("table_id"):
                        fallback_params["table_id"] = params.get("table_id")
                    if params.get("view_id"):
                        fallback_params["view_id"] = params.get("view_id")
                    fallback_params["keyword"] = str(params.get("value") or "")
                    logger.warning(
                        "Exact field not found, fallback to keyword search: %s",
                        fallback_params,
                    )
                    result = await self._mcp.call_tool("feishu.v1.bitable.search_keyword", fallback_params)
                    records = result.get("records", [])
                    schema = result.get("schema")
                    if not records:
                        return self._empty_result("æœªæ‰¾åˆ°ç›¸å…³æ¡ˆä»¶è®°å½•")
                    return self._format_case_result(records, notice=notice, schema=schema)
                except Exception:
                    pass
            logger.error("QuerySkill execution error: %s", e)
            return SkillResult(
                success=False,
                skill_name=self.name,
                message=str(e),
                reply_text="æŸ¥è¯¢å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚",
            )

    def _select_target(self, query: str) -> str:
        """åˆ¤æ–­æŸ¥è¯¢ç±»å‹ï¼ˆè¡¨æ ¼/æ–‡æ¡£ï¼‰"""
        doc_keywords = ["æ–‡æ¡£", "èµ„æ–™", "æ–‡ä»¶", "åˆåŒ"]
        if any(kw in query for kw in doc_keywords):
            return "doc"
        return "bitable"

    def _build_doc_params(self, query: str) -> dict[str, Any]:
        params: dict[str, Any] = {}
        keyword = self._extract_keyword(query)
        if keyword:
            params["keyword"] = keyword
        return params

    def _build_alias_lookup(self, table_aliases: dict[str, Any]) -> dict[str, str]:
        lookup: dict[str, str] = {}
        for table_name, aliases in (table_aliases or {}).items():
            alias_list = [table_name]
            if isinstance(aliases, list):
                alias_list.extend([str(item) for item in aliases if item])
            for alias in alias_list:
                alias = str(alias).strip()
                if not alias:
                    continue
                lookup[alias] = table_name
        return lookup

    def _is_refresh_command(self, query: str) -> bool:
        cmd = query.strip().lower()
        return cmd in {"/refresh", "åˆ·æ–°", "åˆ·æ–°è¡¨ç»“æ„", "åˆ·æ–°è¡¨"}

    async def _refresh_tables(self) -> SkillResult:
        try:
            result = await self._mcp.call_tool(
                "feishu.v1.bitable.list_tables",
                {"refresh": True},
            )
            tables = result.get("tables", [])
            return SkillResult(
                success=True,
                skill_name=self.name,
                data={"tables": tables, "total": result.get("total", len(tables))},
                message="å·²åˆ·æ–°è¡¨ç»“æ„ç¼“å­˜",
                reply_text=f"å·²åˆ·æ–°è¡¨ç»“æ„ç¼“å­˜ï¼ˆ{len(tables)} å¼ è¡¨ï¼‰ã€‚",
            )
        except Exception as exc:
            logger.error("Refresh tables error: %s", exc)
            return SkillResult(
                success=False,
                skill_name=self.name,
                message=str(exc),
                reply_text="åˆ·æ–°è¡¨ç»“æ„å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚",
            )

    def _get_pending_table(self, context: SkillContext) -> dict[str, Any] | None:
        if context.last_skill != self.name:
            return None
        last_result = context.last_result or {}
        pending = last_result.get("pending_table")
        if isinstance(pending, dict):
            return pending
        return None

    def _resolve_pending_response(
        self,
        query: str,
        pending: dict[str, Any],
    ) -> dict[str, Any] | None:
        candidates = pending.get("candidates") or []
        if not isinstance(candidates, list):
            return None
        normalized = query.strip()
        confirm_words = {"æ˜¯", "ç¡®è®¤", "å¯¹", "å¥½çš„", "å¥½", "ok", "yes"}
        if normalized in confirm_words and len(candidates) == 1:
            return candidates[0]
        for candidate in candidates:
            name = candidate.get("table_name")
            if name and name == normalized:
                return candidate
        return None

    async def _resolve_table(self, query: str, extra: dict[str, Any]) -> dict[str, Any]:
        explicit_table_id = str(extra.get("table_id") or "").strip()
        explicit_table_name = str(extra.get("table_name") or "").strip()

        try:
            tables_result = await self._mcp.call_tool("feishu.v1.bitable.list_tables", {})
        except Exception as exc:
            logger.error("List tables failed: %s", exc)
            alias_match = self._match_alias(query)
            if alias_match:
                return {
                    "status": "resolved",
                    "table_name": alias_match,
                    "table_id": None,
                    "confidence": 0.6,
                    "method": "alias_without_tables",
                    "notice": "è¡¨ç»“æ„æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œå·²æŒ‰é»˜è®¤è¡¨æ‰§è¡ŒæŸ¥è¯¢ã€‚",
                }
            return {
                "status": "resolved",
                "table_name": None,
                "table_id": None,
                "confidence": 0.3,
                "method": "default_without_tables",
                "notice": "è¡¨ç»“æ„æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œå·²æŒ‰é»˜è®¤è¡¨æ‰§è¡ŒæŸ¥è¯¢ã€‚",
            }

        tables = tables_result.get("tables", [])
        if not tables:
            return {
                "status": "error",
                "message": "æœªé…ç½®å¤šç»´è¡¨æ ¼",
                "reply_text": "å½“å‰æœªé…ç½®å¤šç»´è¡¨æ ¼ï¼Œæ— æ³•æŸ¥è¯¢ã€‚",
            }

        table_lookup = {item["table_name"]: item.get("table_id") for item in tables}
        table_names = list(table_lookup.keys())

        if explicit_table_id:
            matched_name = next(
                (name for name, tid in table_lookup.items() if tid == explicit_table_id),
                explicit_table_name or None,
            )
            return {
                "status": "resolved",
                "table_name": matched_name,
                "table_id": explicit_table_id,
                "confidence": 1.0,
                "method": "explicit_table_id",
            }

        if explicit_table_name and explicit_table_name in table_lookup:
            return {
                "status": "resolved",
                "table_name": explicit_table_name,
                "table_id": table_lookup.get(explicit_table_name),
                "confidence": 1.0,
                "method": "explicit_table_name",
            }

        if self._is_case_domain_query(query):
            case_table = self._pick_case_default_table(table_names)
            if case_table:
                return {
                    "status": "resolved",
                    "table_name": case_table,
                    "table_id": table_lookup.get(case_table),
                    "confidence": 0.98,
                    "method": "case_default",
                }

        alias_match = self._match_alias(query)
        if alias_match and alias_match in table_lookup:
            logger.info("Table resolved by alias", extra={"table": alias_match, "method": "alias"})
            return {
                "status": "resolved",
                "table_name": alias_match,
                "table_id": table_lookup.get(alias_match),
                "confidence": 1.0,
                "method": "alias",
            }

        direct_match = self._match_table_name(query, table_names)
        if direct_match:
            logger.info("Table resolved by name", extra={"table": direct_match, "method": "direct"})
            return {
                "status": "resolved",
                "table_name": direct_match,
                "table_id": table_lookup.get(direct_match),
                "confidence": 1.0,
                "method": "direct",
            }

        llm_result = await self._llm_pick_table(query, table_names)
        candidates = self._normalize_candidates(llm_result.get("candidates"), table_names)
        if llm_result.get("table_name"):
            candidates = [llm_result["table_name"]] + [c for c in candidates if c != llm_result["table_name"]]
        candidates = candidates[: self._max_candidates]

        confidence = float(llm_result.get("confidence") or 0)
        selected = llm_result.get("table_name")
        if selected and selected not in table_lookup:
            selected = None

        logger.info(
            "Table resolved by llm",
            extra={
                "table": selected,
                "confidence": confidence,
                "candidates": candidates,
            },
        )

        if selected and confidence >= self._auto_confirm_threshold:
            return {
                "status": "resolved",
                "table_name": selected,
                "table_id": table_lookup.get(selected),
                "confidence": confidence,
                "method": "llm_high",
            }
        if selected and confidence >= self._confidence_threshold:
            return {
                "status": "resolved",
                "table_name": selected,
                "table_id": table_lookup.get(selected),
                "confidence": confidence,
                "method": "llm_medium",
                "notice": f"å·²ä¸ºæ‚¨å®šä½åˆ° {selected} è¡¨ã€‚",
            }

        reply_text = self._build_confirmation_reply(candidates, table_names)
        pending_table = {
            "query": query,
            "candidates": [
                {"table_name": name, "table_id": table_lookup.get(name)} for name in candidates
            ],
        }
        return {
            "status": "need_confirm",
            "reply_text": reply_text,
            "pending_table": pending_table,
        }

    def _match_alias(self, query: str) -> str | None:
        logger.info(f"Matching alias for query: '{query}', alias_lookup: {self._alias_lookup}")
        query_lower = query.lower()
        matched = []
        for alias, table in self._alias_lookup.items():
            if alias in query or alias.lower() in query_lower:
                matched.append((len(alias), table))
                logger.info(f"Matched alias: '{alias}' -> '{table}'")
        if not matched:
            logger.warning("No alias matched")
            return None
        matched.sort(reverse=True)
        result = matched[0][1]
        logger.info(f"Selected table: '{result}'")
        return result

    def _match_table_name(self, query: str, table_names: list[str]) -> str | None:
        matched = [name for name in table_names if name and name in query]
        if not matched:
            return None
        matched.sort(key=len, reverse=True)
        return matched[0]

    def _is_case_domain_query(self, query: str) -> bool:
        normalized = query.replace(" ", "")
        keywords = ["å¼€åº­", "åº­å®¡", "æ¡ˆä»¶", "æ¡ˆå­", "æ¡ˆå·", "å®¡ç†", "æ³•é™¢", "å§”æ‰˜äºº", "å¯¹æ–¹å½“äº‹äºº"]
        return any(token in normalized for token in keywords) or self._is_hearing_query(normalized)

    def _pick_case_default_table(self, table_names: list[str]) -> str | None:
        preferred = ["æ¡ˆä»¶é¡¹ç›®æ€»åº“", "æ¡ˆä»¶ é¡¹ç›®æ€»åº“", "ã€è¯‰è®¼æ¡ˆä»¶ã€‘", "è¯‰è®¼æ¡ˆä»¶"]
        for name in preferred:
            if name in table_names:
                return name
        for name in table_names:
            if "æ¡ˆä»¶" in name and ("åº“" in name or "å°è´¦" in name):
                return name
        return None

    async def _llm_pick_table(self, query: str, table_names: list[str]) -> dict[str, Any]:
        if not self._llm or not table_names:
            return {}
        system = "ä½ æ˜¯è¡¨åè¯†åˆ«åŠ©æ‰‹ã€‚"
        prompt = (
            "è¯·æ ¹æ®ç”¨æˆ·é—®é¢˜ä»è¡¨ååˆ—è¡¨ä¸­é€‰æ‹©æœ€å¯èƒ½çš„è¡¨ï¼Œå¹¶è¿”å› JSONï¼š"
            "{\"table_name\": \"...\", \"confidence\": 0.0-1.0, \"reason\": \"...\", "
            "\"candidates\": [\"...\", \"...\"]}ã€‚åªè¿”å› JSONã€‚\n\n"
            f"è¡¨ååˆ—è¡¨ï¼š{', '.join(table_names)}\n"
            f"ç”¨æˆ·é—®é¢˜ï¼š{query}"
        )
        try:
            return await self._llm.chat_json(prompt, system=system)
        except Exception as exc:
            logger.warning("LLM table match failed: %s", exc)
            return {}

    def _normalize_candidates(self, candidates: Any, table_names: list[str]) -> list[str]:
        result: list[str] = []
        if isinstance(candidates, list):
            for item in candidates:
                if isinstance(item, str) and item in table_names:
                    result.append(item)
        return result

    def _build_confirmation_reply(self, candidates: list[str], all_tables: list[str]) -> str:
        templates = (self._table_recognition.get("templates") or {})
        single_tpl = templates.get("single_candidate", "è¯·ç¡®è®¤è¡¨åï¼š{table_name}")
        multi_tpl = templates.get("multi_candidate", "è¯·ç¡®è®¤è¡¨åï¼š\n{candidate_list}")
        no_match_tpl = templates.get("no_match", "å¯ç”¨è¡¨ï¼š{all_tables}")

        if len(candidates) == 1:
            return single_tpl.format(table_name=candidates[0])
        if 1 < len(candidates) <= self._max_candidates:
            candidate_list = "\n".join([f"- {name}" for name in candidates])
            return multi_tpl.format(candidate_list=candidate_list)
        return no_match_tpl.format(all_tables="ã€".join(all_tables))

    def _build_bitable_params(
        self,
        query: str,
        extra: dict[str, Any],
        table_result: dict[str, Any],
    ) -> tuple[str, dict[str, Any]]:
        params: dict[str, Any] = {}
        selected_tool: str | None = None

        pagination = extra.get("pagination") if isinstance(extra.get("pagination"), dict) else None
        if isinstance(pagination, dict) and pagination.get("tool"):
            base_params_raw = pagination.get("params")
            if isinstance(base_params_raw, dict):
                base_params: dict[str, Any] = {str(k): v for k, v in base_params_raw.items()}
                params.update(base_params)
            if pagination.get("page_token"):
                params["page_token"] = pagination.get("page_token")
            logger.info("Query scenario: pagination_next")
            return str(pagination.get("tool")), params

        planner_plan = extra.get("planner_plan") if isinstance(extra.get("planner_plan"), dict) else None
        if isinstance(planner_plan, dict):
            mapped_tool = self._map_planner_tool(str(planner_plan.get("tool") or ""))
            if mapped_tool:
                plan_params_raw = planner_plan.get("params")
                plan_params: dict[str, Any] = {}
                if isinstance(plan_params_raw, dict):
                    plan_params = {str(k): v for k, v in plan_params_raw.items()}
                params.update(plan_params)

                intent = str(planner_plan.get("intent") or "")
                if mapped_tool == "feishu.v1.bitable.search" and intent == "query_all":
                    params.setdefault("ignore_default_view", True)

                if mapped_tool == "feishu.v1.bitable.search_date_range":
                    guessed_field = self._guess_date_field(query)
                    current_field = str(params.get("field") or "").strip()
                    if guessed_field and (not current_field or current_field in {"æˆªæ­¢æ—¥", "æ—¥æœŸ", "æ—¶é—´"}):
                        params["field"] = guessed_field

                    if extra.get("date_from"):
                        params.setdefault("date_from", extra.get("date_from"))
                    if extra.get("date_to"):
                        params.setdefault("date_to", extra.get("date_to"))
                    if extra.get("time_from"):
                        params.setdefault("time_from", extra.get("time_from"))
                    if extra.get("time_to"):
                        params.setdefault("time_to", extra.get("time_to"))
                    if not params.get("date_from") or not params.get("date_to"):
                        parsed = parse_time_range(query)
                        if parsed:
                            params.setdefault("date_from", parsed.date_from)
                            params.setdefault("date_to", parsed.date_to)
                            if parsed.time_from:
                                params.setdefault("time_from", parsed.time_from)
                            if parsed.time_to:
                                params.setdefault("time_to", parsed.time_to)
                        elif any(token in query for token in ["æœ€è¿‘", "è¿‘æœŸ", "æœ€æ–°"]):
                            today = date.today()
                            params.setdefault("date_from", (today - timedelta(days=30)).isoformat())
                            params.setdefault("date_to", (today + timedelta(days=30)).isoformat())

                if mapped_tool == "feishu.v1.bitable.search":
                    parsed = parse_time_range(query)
                    if parsed and self._is_hearing_query(query):
                        mapped_tool = "feishu.v1.bitable.search_date_range"
                        params["field"] = params.get("field") or "å¼€åº­æ—¥"
                        params.setdefault("date_from", parsed.date_from)
                        params.setdefault("date_to", parsed.date_to)
                        if parsed.time_from:
                            params.setdefault("time_from", parsed.time_from)
                        if parsed.time_to:
                            params.setdefault("time_to", parsed.time_to)

                if mapped_tool == "feishu.v1.bitable.search_person" and not params.get("open_id"):
                    user_profile = extra.get("user_profile")
                    open_id = getattr(user_profile, "open_id", "") if user_profile else ""
                    if open_id:
                        params["open_id"] = open_id
                if mapped_tool == "feishu.v1.bitable.search_person" and not params.get("user_name"):
                    user_profile = extra.get("user_profile")
                    user_name = getattr(user_profile, "lawyer_name", "") if user_profile else ""
                    if not user_name:
                        user_name = getattr(user_profile, "name", "") if user_profile else ""
                    if user_name:
                        params["user_name"] = user_name
                if mapped_tool == "feishu.v1.bitable.search_person" and not params.get("user_name"):
                    entity_keyword = self._extract_entity_keyword(query)
                    if entity_keyword:
                        params["user_name"] = entity_keyword
                if mapped_tool == "feishu.v1.bitable.search_person" and not params.get("field"):
                    params["field"] = "ä¸»åŠå¾‹å¸ˆ"

                if mapped_tool == "feishu.v1.bitable.search_exact" and not params.get("value"):
                    exact = self._extract_exact_field(query)
                    if exact:
                        params.setdefault("field", exact.get("field"))
                        params["value"] = exact.get("value")

                if mapped_tool == "feishu.v1.bitable.search" and not any(
                    params.get(k) for k in ("keyword", "date_from", "date_to", "filters")
                ):
                    exact = self._extract_exact_field(query)
                    if exact:
                        mapped_tool = "feishu.v1.bitable.search_exact"
                        params.update(exact)
                    else:
                        entity_keyword = self._extract_entity_keyword(query)
                        keyword = entity_keyword or self._extract_keyword(query)
                        if keyword:
                            mapped_tool = "feishu.v1.bitable.search_keyword"
                            params["keyword"] = keyword
                            params.setdefault("fields", self._build_keyword_fields())

                if mapped_tool == "feishu.v1.bitable.search_keyword" and not params.get("fields"):
                    params["fields"] = self._build_keyword_fields()

                if mapped_tool == "feishu.v1.bitable.search_keyword" and params.get("keyword"):
                    params["keyword"] = self._sanitize_search_keyword(str(params.get("keyword") or ""))

                if mapped_tool == "feishu.v1.bitable.search_exact" and params.get("value"):
                    params["value"] = self._sanitize_search_keyword(str(params.get("value") or ""))

                if mapped_tool == "feishu.v1.bitable.search_exact":
                    exact_field = str(params.get("field") or "").strip()
                    exact_value = str(params.get("value") or "").strip()
                    entity_keyword = self._extract_entity_keyword(query)
                    if exact_field in {"ä¸»åŠå¾‹å¸ˆ", "ååŠå¾‹å¸ˆ"} and (
                        self._looks_like_org_name(exact_value) or self._looks_like_org_name(entity_keyword)
                    ):
                        mapped_tool = "feishu.v1.bitable.search_keyword"
                        params.pop("value", None)
                        params["keyword"] = self._sanitize_search_keyword(entity_keyword or exact_value)
                        params.setdefault("fields", self._build_keyword_fields())

                if mapped_tool in {
                    "feishu.v1.bitable.search_keyword",
                    "feishu.v1.bitable.search_exact",
                    "feishu.v1.bitable.search_person",
                    "feishu.v1.bitable.search_date_range",
                }:
                    self._maybe_ignore_default_view(params, query)

                selected_tool = mapped_tool

                logger.info("Query scenario: planner")

        table_id = table_result.get("table_id")
        if table_id:
            params["table_id"] = table_id

        if isinstance(planner_plan, dict):
            mapped_tool = selected_tool or self._map_planner_tool(str(planner_plan.get("tool") or ""))
            if mapped_tool:
                if mapped_tool == "feishu.v1.bitable.search_person" and not (
                    params.get("open_id") or params.get("user_name")
                ):
                    mapped_tool = None
                if mapped_tool == "feishu.v1.bitable.search_exact" and (not params.get("field") or not params.get("value")):
                    mapped_tool = None
                if mapped_tool == "feishu.v1.bitable.search_keyword" and not params.get("keyword"):
                    mapped_tool = None
                if mapped_tool == "feishu.v1.bitable.search_date_range" and (not params.get("date_from") or not params.get("date_to")):
                    mapped_tool = None

            if mapped_tool:
                return mapped_tool, params

        if self._is_all_cases_query(query):
            if self._all_cases_ignore_default_view and not self._should_keep_view_filter(query):
                params["ignore_default_view"] = True
            logger.info("Query scenario: all_cases")
            return "feishu.v1.bitable.search", params

        # ä¼˜å…ˆçº§1: æ£€æŸ¥æ˜¯å¦ä¸º"æˆ‘çš„æ¡ˆä»¶"æŸ¥è¯¢
        user_profile = extra.get("user_profile")
        if user_profile and user_profile.open_id and ("æˆ‘çš„" in query or "è‡ªå·±çš„" in query):
            # ä½¿ç”¨äººå‘˜å­—æ®µæœç´¢å·¥å…·ï¼Œé€šè¿‡ open_id ç²¾ç¡®åŒ¹é…ä¸»åŠå¾‹å¸ˆ
            logger.info(f"Query 'my cases' for user: {user_profile.name} (open_id: {user_profile.open_id})")
            params.update({
                "field": "ä¸»åŠå¾‹å¸ˆ",
                "open_id": user_profile.open_id,
            })
            if getattr(user_profile, "lawyer_name", None):
                params["user_name"] = user_profile.lawyer_name
            elif getattr(user_profile, "name", None):
                params["user_name"] = user_profile.name
            self._maybe_ignore_default_view(params, query)
            logger.info("Query scenario: my_cases")
            return "feishu.v1.bitable.search_person", params

        # ä¼˜å…ˆçº§2: æå–â€œXçš„æ¡ˆä»¶/é¡¹ç›®â€ä¸»ä½“å…³é”®è¯
        entity_keyword = self._extract_entity_keyword(query)
        if entity_keyword:
            logger.info("Query scenario: entity_cases (%s)", entity_keyword)
            params["keyword"] = entity_keyword
            params["fields"] = self._build_keyword_fields()
            self._maybe_ignore_default_view(params, query)
            return "feishu.v1.bitable.search_keyword", params

        date_from = extra.get("date_from")
        date_to = extra.get("date_to")
        time_from = extra.get("time_from")
        time_to = extra.get("time_to")
        if not date_from or not date_to:
            parsed = parse_time_range(query)
            if parsed:
                date_from = date_from or parsed.date_from
                date_to = date_to or parsed.date_to
                time_from = time_from or parsed.time_from
                time_to = time_to or parsed.time_to
        if date_from or date_to:
            params.update({
                "field": self._guess_date_field(query),
                "date_from": date_from,
                "date_to": date_to,
            })
            if time_from:
                params["time_from"] = time_from
            if time_to:
                params["time_to"] = time_to
            self._maybe_ignore_default_view(params, query)
            return "feishu.v1.bitable.search_date_range", params

        exact_field = self._extract_exact_field(query)
        if exact_field:
            params.update(exact_field)
            self._maybe_ignore_default_view(params, query)
            logger.info("Query scenario: exact_match")
            return "feishu.v1.bitable.search_exact", params

        keyword = self._extract_keyword(query)
        if keyword:
            params["keyword"] = keyword
            params["fields"] = self._build_keyword_fields()
            self._maybe_ignore_default_view(params, query)
            logger.info("Query scenario: keyword")
            return "feishu.v1.bitable.search_keyword", params

        if self._all_cases_ignore_default_view and not self._should_keep_view_filter(query):
            params["ignore_default_view"] = True
        logger.info("Query scenario: full_scan")
        return "feishu.v1.bitable.search", params

    def _map_planner_tool(self, tool: str) -> str | None:
        mapping = {
            "search": "feishu.v1.bitable.search",
            "search_exact": "feishu.v1.bitable.search_exact",
            "search_keyword": "feishu.v1.bitable.search_keyword",
            "search_person": "feishu.v1.bitable.search_person",
            "search_date_range": "feishu.v1.bitable.search_date_range",
            "search_advanced": "feishu.v1.bitable.search_advanced",
        }
        if tool in mapping:
            return mapping[tool]
        if tool.startswith("feishu.v1.bitable."):
            return tool
        return None

    def _is_all_cases_query(self, query: str) -> bool:
        normalized = query.replace(" ", "")
        if any(token in normalized for token in self._all_cases_keywords):
            return True
        if ("æ‰€æœ‰" in normalized or "å…¨éƒ¨" in normalized) and ("æ¡ˆä»¶" in normalized or "é¡¹ç›®" in normalized):
            return True
        return False

    def _should_keep_view_filter(self, query: str) -> bool:
        normalized = query.replace(" ", "")
        return any(token in normalized for token in self._keep_view_keywords)

    def _guess_date_field(self, query: str) -> str:
        normalized = query.replace(" ", "")
        if "ç®¡è¾–æƒå¼‚è®®" in normalized:
            return "ç®¡è¾–æƒå¼‚è®®æˆªæ­¢æ—¥"
        if "ä¸¾è¯" in normalized:
            return "ä¸¾è¯æˆªæ­¢æ—¥"
        if "æŸ¥å°" in normalized:
            return "æŸ¥å°åˆ°æœŸæ—¥"
        if "ä¸Šè¯‰" in normalized:
            return "ä¸Šè¯‰æˆªæ­¢æ—¥"
        if self._is_hearing_query(normalized):
            return "å¼€åº­æ—¥"
        if "æˆªæ­¢" in normalized or "åˆ°æœŸ" in normalized:
            return "æˆªæ­¢æ—¥"
        return "å¼€åº­æ—¥"

    def _is_hearing_query(self, query: str) -> bool:
        normalized = query.replace(" ", "")
        if "å¼€åº­" in normalized or "åº­å®¡" in normalized or "åº­è¦å¼€" in normalized:
            return True
        return bool(re.search(r"åº­.*å¼€|å¼€.*åº­", normalized))

    def _extract_exact_field(self, query: str) -> dict[str, str] | None:
        exact_patterns: list[tuple[str, str]] = [
            (r"(?:æ¡ˆå·|æ¡ˆä»¶å·)[æ˜¯ä¸º:ï¼š\s]*([A-Za-z0-9\-_/ï¼ˆï¼‰()_\u4e00-\u9fa5]+)", "æ¡ˆå·"),
            (r"(?:é¡¹ç›®ID|é¡¹ç›®Id|é¡¹ç›®id|é¡¹ç›®ç¼–å·|é¡¹ç›®å·)[æ˜¯ä¸º:ï¼š\s]*([A-Za-z0-9\-_/ï¼ˆï¼‰()_\u4e00-\u9fa5]+)", "é¡¹ç›®ID"),
            (r"(?:ç¼–å·)[æ˜¯ä¸º:ï¼š\s]*([A-Za-z0-9\-_/ï¼ˆï¼‰()_\u4e00-\u9fa5]+)", "æ¡ˆå·"),
        ]
        for pattern, field in exact_patterns:
            match = re.search(pattern, query)
            if not match:
                continue
            value = match.group(1).strip()
            value = re.sub(r"(?:çš„)?(?:æ¡ˆä»¶|æ¡ˆå­|é¡¹ç›®)$", "", value).strip()
            value = self._sanitize_search_keyword(value)
            if value:
                return {"field": field, "value": value}
        return None

    def _extract_entity_keyword(self, query: str) -> str:
        """æå–â€œXçš„æ¡ˆä»¶/æ¡ˆå­/é¡¹ç›®â€ä¸­çš„ä¸»ä½“å…³é”®è¯ã€‚"""
        if "æ¡ˆå·" in query or "é¡¹ç›®ID" in query or "é¡¹ç›®ç¼–å·" in query:
            return ""

        compact = re.sub(r"[ï¼Œã€‚,.!?ï¼Ÿ!ï¼š:ï¼›;]", " ", query)
        pattern = re.compile(
            r"(?:å¸®æˆ‘|è¯·|éº»çƒ¦)?(?:æŸ¥æ‰¾|æŸ¥è¯¢|æœç´¢|æŸ¥ä¸€æŸ¥|æŸ¥ä¸€ä¸‹|æŸ¥|æ‰¾|çœ‹çœ‹|çœ‹ä¸‹|çœ‹ä¸€ä¸‹|æŸ¥çœ‹|å¸®æˆ‘æŸ¥)?\s*(?:ä¸€ä¸‹)?\s*([^\s]{2,60}?)(?:çš„)?(?:æ¡ˆä»¶|æ¡ˆå­|é¡¹ç›®)"
        )
        match = pattern.search(compact)
        if not match:
            return ""

        candidate = match.group(1).strip()
        candidate = self._sanitize_search_keyword(candidate)
        candidate = re.sub(r"^(æˆ‘çš„|æˆ‘è´Ÿè´£çš„|æˆ‘è´Ÿè´£|è‡ªå·±çš„|æœ‰å…³|å…³äº)", "", candidate).strip()
        candidate = re.sub(r"(è´Ÿè´£çš„?|ç›¸å…³çš„?|æœ‰å…³çš„?)$", "", candidate).strip()
        if not candidate:
            return ""
        if candidate in {"æˆ‘", "è‡ªå·±", "æ‰€æœ‰", "å…¨éƒ¨", "ä»Šå¤©", "æ˜å¤©", "æœ¬å‘¨", "æœ¬æœˆ", "æœ€è¿‘", "è¿‘æœŸ"}:
            return ""
        return candidate

    def _apply_keyword_relevance(self, records: list[dict[str, Any]], keyword: str) -> list[dict[str, Any]]:
        """å¯¹ç»“æœè¿›è¡Œæœ¬åœ°ç›¸å…³æ€§è¿‡æ»¤ï¼Œé¿å…å…¨è¡¨å™ªå£°è®°å½•ã€‚"""
        target = keyword.strip().lower()
        if not target:
            return records

        high_priority_fields = {
            self._display_fields.get("title_left", "å§”æ‰˜äºº"),
            self._display_fields.get("title_right", "å¯¹æ–¹å½“äº‹äºº"),
            self._display_fields.get("case_no", "æ¡ˆå·"),
            "å§”æ‰˜äºº",
            "å¯¹æ–¹å½“äº‹äºº",
            "æ¡ˆå·",
            "é¡¹ç›®ID",
        }

        scored: list[tuple[int, dict[str, Any]]] = []
        for record in records:
            fields = record.get("fields_text") or record.get("fields") or {}
            score = 0
            for field_name, value in fields.items():
                text = str(value or "").strip().lower()
                if not text or target not in text:
                    continue
                score += 3 if str(field_name) in high_priority_fields else 1
            scored.append((score, record))

        matched = [record for score, record in scored if score > 0]
        if not matched:
            return records
        scored.sort(key=lambda item: item[0], reverse=True)
        return [record for score, record in scored if score > 0]

    def _build_keyword_fields(self) -> list[str]:
        fields: list[str] = []
        for key in ("title_left", "title_right", "title_suffix", "case_no", "court", "stage"):
            value = str(self._display_fields.get(key, "")).strip()
            if value and value not in fields:
                fields.append(value)
        for value in self._keyword_fields:
            field = str(value).strip()
            if field and field not in fields:
                fields.append(field)
        return fields

    def _maybe_ignore_default_view(self, params: dict[str, Any], query: str) -> None:
        if self._should_keep_view_filter(query):
            return
        if "view_id" in params:
            return
        params.setdefault("ignore_default_view", True)

    def _extract_keyword(self, query: str) -> str:
        """
        æå–å…³é”®è¯

        é€»è¾‘:
            - å»é™¤å¸¸è§æ— æ•ˆè¯ï¼ˆå¦‚åŠ¨ä½œè¯ã€é€šç”¨è¯ï¼‰
            - å¦‚æœè¿‡æ»¤åæ— æœ‰æ•ˆå…³é”®è¯ï¼Œè¿”å›ç©ºï¼ˆæŸ¥è¯¢å…¨éƒ¨ï¼‰

        å‚æ•°:
            query: åŸå§‹æŸ¥è¯¢æ–‡æœ¬
        è¿”å›:
            å¤„ç†åçš„å…³é”®è¯
        """
        keyword = query
        
        # æŸ¥è¯¢åŠ¨ä½œè¯ï¼ˆéœ€è¦å»é™¤ï¼‰
        action_words = [
            "æ‰¾ä¸€ä¸‹", "æŸ¥ä¸€ä¸‹", "æŸ¥è¯¢", "æœç´¢", "å¸®æˆ‘", "è¯·å¸®æˆ‘", 
            "æŸ¥", "æ‰¾", "æœ", "æŸ¥çœ‹", "çœ‹ä¸‹", "çœ‹ä¸€ä¸‹",
            "ä¸€ä¸‹", "ä½ èƒ½", "èƒ½ä¸èƒ½", "å¯ä»¥", "è¯·",
        ]
        
        # é€šç”¨è¯­ä¹‰è¯ï¼ˆéœ€è¦å»é™¤ï¼Œä½†ä¸æ˜¯å…³é”®è¯ï¼‰
        general_words = [
            "æ¡ˆå­", "æ¡ˆä»¶", "æœ‰ä»€ä¹ˆ", "æœ‰å“ªäº›", "éƒ½æœ‰å“ªäº›", "ç›®å‰",
            "åº­è¦å¼€", "åº­å®¡", "ä¿¡æ¯", "è¯¦æƒ…", "çš„", "å—", "å‘¢",
            "çœ‹çœ‹", "å‘Šè¯‰æˆ‘", "åˆ—å‡º", "å¾‹å¸ˆ", "æ³•å®˜", "å½“äº‹äºº",
            "å§”æ‰˜äºº", "è¢«å‘Š", "åŸå‘Š", "å¼€åº­", "æ¡ˆ",
            "æ‰€æœ‰", "å…¨éƒ¨", "åˆ—è¡¨", "å…¨éƒ¨æ¡ˆä»¶", "æ‰€æœ‰æ¡ˆä»¶", "å…¨éƒ¨é¡¹ç›®", "æ‰€æœ‰é¡¹ç›®",
        ]
        
        for word in action_words + general_words:
            keyword = keyword.replace(word, "")

        keyword = self._sanitize_search_keyword(keyword)

        # å¦‚æœå…³é”®è¯å¤ªçŸ­æˆ–åªæ˜¯å¸¸è§è¯ï¼Œè¿”å›ç©ºï¼ˆæŸ¥è¯¢å…¨éƒ¨ï¼‰
        if len(keyword) <= 1:
            return ""
            
        return keyword

    def _sanitize_search_keyword(self, keyword: str) -> str:
        cleaned = str(keyword or "").strip()
        if not cleaned:
            return ""

        cleaned = re.sub(r"^[\s'\"â€œâ€â€˜â€™]+|[\s'\"â€œâ€â€˜â€™]+$", "", cleaned)
        cleaned = re.sub(
            r"^(?:å¸®æˆ‘|è¯·|éº»çƒ¦|æŸ¥è¯¢|æŸ¥æ‰¾|æœç´¢|æŸ¥çœ‹|çœ‹ä¸‹|çœ‹ä¸€ä¸‹|çœ‹çœ‹|çœ‹|æŸ¥ä¸€ä¸‹|æŸ¥ä¸€æŸ¥|æŸ¥|æ‰¾|ä¸€ä¸‹|å¸®å¿™|æˆ‘æƒ³|æˆ‘æƒ³æŸ¥)+",
            "",
            cleaned,
        ).strip()
        cleaned = re.sub(r"^(?:æ¡ˆå·(?:ä¸º|æ˜¯)?|é¡¹ç›®ID(?:ä¸º|æ˜¯)?|é¡¹ç›®ç¼–å·(?:ä¸º|æ˜¯)?|ç¼–å·(?:ä¸º|æ˜¯)?)", "", cleaned).strip()
        cleaned = re.sub(r"(?:çš„)?(?:æ¡ˆä»¶|æ¡ˆå­|é¡¹ç›®|ä¿¡æ¯)$", "", cleaned).strip()
        cleaned = re.sub(r"^(?:ä¸€ä¸‹)+", "", cleaned).strip()
        cleaned = re.sub(r"\s+", "", cleaned)

        if cleaned in {"æœ€è¿‘", "è¿‘æœŸ", "æœ€æ–°", "ä¸€ä¸‹", "æŸ¥è¯¢", "æŸ¥çœ‹", "æŸ¥", "æ‰¾"}:
            return ""
        return cleaned

    def _looks_like_org_name(self, text: str) -> bool:
        normalized = str(text or "").strip()
        if len(normalized) < 4:
            return False
        org_tokens = ("å…¬å¸", "é›†å›¢", "æœ‰é™å…¬å¸", "æœ‰é™è´£ä»»", "è‚¡ä»½", "äº‹åŠ¡æ‰€", "ä¸­å¿ƒ")
        return any(token in normalized for token in org_tokens)

    # ============================================
    # region å›å¤æ¨¡æ¿åŠ è½½
    # ============================================
    def _load_response_pool(self) -> dict[str, list[str]]:
        """ä» config/responses.yaml åŠ è½½ä¸šåŠ¡å›å¤æ¨¡æ¿"""
        defaults = {
            "result_opener": ["æŸ¥åˆ°å•¦~ "],
            "empty_result": ["æœªæ‰¾åˆ°ç›¸å…³è®°å½•ï¼Œè¯·å°è¯•è°ƒæ•´æŸ¥è¯¢æ¡ä»¶ã€‚"],
        }
        responses_path = Path("config/responses.yaml")
        if not responses_path.exists():
            return defaults
        try:
            data = yaml.safe_load(responses_path.read_text(encoding="utf-8")) or {}
            for key in defaults:
                val = data.get(key)
                if isinstance(val, list) and val:
                    defaults[key] = val
            return defaults
        except Exception as exc:
            logger.warning("Failed to load responses.yaml for QuerySkill: %s", exc)
            return defaults
    # endregion
    # ============================================

    def _empty_result(self, message: str, prefer_message: bool = False) -> SkillResult:
        """æ„é€ ç©ºç»“æœå“åº”ï¼ˆéšæœºåŒ–ï¼‰"""
        pool = self._response_pool.get("empty_result")
        if prefer_message and message:
            reply = message
        else:
            reply = random.choice(pool) if pool else f"{message}ï¼Œè¯·å°è¯•è°ƒæ•´æŸ¥è¯¢æ¡ä»¶ã€‚"
        return SkillResult(
            success=True,
            skill_name=self.name,
            data={"records": [], "total": 0},
            message=message,
            reply_text=reply,
        )

    def _format_case_result(
        self,
        records: list[dict[str, Any]],
        notice: str | None = None,
        schema: list[dict[str, Any]] | None = None,
        pagination: dict[str, Any] | None = None,
        query_meta: dict[str, Any] | None = None,
    ) -> SkillResult:
        """æ ¼å¼åŒ–æ¡ˆä»¶æŸ¥è¯¢ç»“æœ"""
        count = len(records)
        total = None
        if isinstance(pagination, dict):
            total = pagination.get("total")
        title_count = total if isinstance(total, int) and total >= count else count
        # éšæœºå¼€åœºç™½
        opener_pool = self._response_pool.get("result_opener")
        opener = random.choice(opener_pool) if opener_pool else ""
        title = f"{opener}ğŸ“Œ æ¡ˆä»¶æŸ¥è¯¢ç»“æœï¼ˆå…± {title_count} æ¡ï¼‰"
        
        items = []
        df = self._display_fields  # ä½¿ç”¨é…ç½®çš„å­—æ®µå
        for i, record in enumerate(records, start=1):
            fields = record.get("fields_text") or record.get("fields", {})
            left = self._clean_text_value(fields.get(df.get("title_left", ""), ""))
            right = self._clean_text_value(fields.get(df.get("title_right", ""), ""))
            suffix = self._clean_text_value(fields.get(df.get("title_suffix", ""), ""))
            case_no = self._clean_text_value(fields.get(df.get("case_no", "æ¡ˆå·"), ""))
            court = self._clean_text_value(fields.get(df.get("court", "å®¡ç†æ³•é™¢"), ""))
            stage = self._clean_text_value(fields.get(df.get("stage", "ç¨‹åºé˜¶æ®µ"), ""))
            item = (
                f"{i}ï¸âƒ£ {left} vs {right}ï½œ{suffix}\n"
                f"   â€¢ æ¡ˆå·ï¼š{case_no}\n"
                f"   â€¢ æ³•é™¢ï¼š{court}\n"
                f"   â€¢ ç¨‹åºï¼š{stage}\n"
                f"   â€¢ ğŸ”— æŸ¥çœ‹è¯¦æƒ…ï¼š{record.get('record_url', '')}"
            )
            items.append(item)
        
        parts = [title]
        if notice:
            parts = [notice, "", title]
        if pagination and pagination.get("has_more"):
            parts.append("å›å¤â€œä¸‹ä¸€é¡µâ€æŸ¥çœ‹æ›´å¤šã€‚")
        reply_text = "\n\n".join(parts + items)
        
        # æ„å»ºå¡ç‰‡
        card = self._build_card(title, items, notice=notice)
        
        return SkillResult(
            success=True,
            skill_name=self.name,
            data={
                "records": records,
                "total": title_count,
                "schema": schema or [],
                "pagination": pagination or {
                    "has_more": False,
                    "page_token": "",
                    "current_page": 1,
                    "total": title_count,
                },
                "query_meta": query_meta or {},
            },
            message=f"æŸ¥è¯¢åˆ° {count} æ¡è®°å½•",
            reply_type="card",
            reply_text=reply_text,
            reply_card=card,
        )

    def _clean_text_value(self, value: Any) -> str:
        text = str(value or "")
        text = text.replace("\r", " ").replace("\n", " ")
        text = re.sub(r"\s*,\s*", "ï¼Œ", text)
        text = re.sub(r"\s+", " ", text)
        return text.strip(" ï¼Œ")

    def _format_doc_result(self, documents: list[dict[str, Any]]) -> SkillResult:
        """æ ¼å¼åŒ–æ–‡æ¡£æŸ¥è¯¢ç»“æœ"""
        count = len(documents)
        title = f"ğŸ“„ æ–‡æ¡£æœç´¢ç»“æœï¼ˆå…± {count} æ¡ï¼‰"
        
        items = []
        for i, doc in enumerate(documents, start=1):
            item = (
                f"{i}. {doc.get('title', 'æœªå‘½åæ–‡æ¡£')}\n"
                f"   {doc.get('preview', '')}\n"
                f"   ğŸ”— {doc.get('url', '')}"
            )
            items.append(item)
        
        reply_text = "\n\n".join([title] + items)
        
        return SkillResult(
            success=True,
            skill_name=self.name,
            data={"documents": documents, "total": count},
            message=f"æœç´¢åˆ° {count} ç¯‡æ–‡æ¡£",
            reply_type="text",
            reply_text=reply_text,
        )

    def _build_card(self, title: str, items: list[str], notice: str | None = None) -> dict[str, Any]:
        """æ„å»ºé£ä¹¦æ¶ˆæ¯å¡ç‰‡"""
        elements = []
        if notice:
            elements.append({"tag": "markdown", "content": notice})
        elements.extend({"tag": "markdown", "content": item} for item in items)
        return {
            "config": {"wide_screen_mode": True},
            "header": {
                "title": {"tag": "plain_text", "content": title},
            },
            "elements": elements,
        }
# endregion
