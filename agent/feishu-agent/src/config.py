"""
æè¿°: Feishu Agent å…¨å±€é…ç½®åŠ è½½å™¨
ä¸»è¦åŠŸèƒ½:
    - ç»Ÿä¸€ç®¡ç†åº”ç”¨é…ç½® (Settings)
    - æ”¯æŒ YAML æ–‡ä»¶åŠ è½½ä¸ç¯å¢ƒå˜é‡è¦†ç›– (Env Override)
    - æä¾› Pydantic ç±»å‹æ ¡éªŒ
"""

from __future__ import annotations

import os
import re
from functools import lru_cache
from pathlib import Path
from typing import Any

import yaml
from pydantic import BaseModel, Field


_ENV_PATTERN = re.compile(r"\$\{([^}]+)\}")


# region é…ç½®æ¨¡å‹å®šä¹‰
class ServerSettings(BaseModel):
    """æœåŠ¡å™¨é…ç½®"""
    host: str = "0.0.0.0"
    port: int = 8080
    workers: int = 1
    debug: bool = False


class FeishuMessageSettings(BaseModel):
    reply_timeout: int = 30
    use_reply_mode: bool = True


class FeishuSettings(BaseModel):
    """é£ä¹¦å¼€æ”¾å¹³å°é…ç½®"""
    app_id: str = ""
    app_secret: str = ""
    verification_token: str = ""
    encrypt_key: str | None = None
    api_base: str = "https://open.feishu.cn/open-apis"
    message: FeishuMessageSettings = Field(default_factory=FeishuMessageSettings)


class MCPRequestSettings(BaseModel):
    timeout: int = 30
    max_retries: int = 2
    retry_delay: float = 1.0


class MCPSettings(BaseModel):
    """MCP Server è¿æ¥é…ç½®"""
    base_url: str = "http://localhost:8081"
    request: MCPRequestSettings = Field(default_factory=MCPRequestSettings)


class PostgresSettings(BaseModel):
    """PostgreSQL æ•°æ®åº“é…ç½®"""
    dsn: str = ""
    min_size: int = 1
    max_size: int = 5
    timeout: int = 10


class LLMFallbackSettings(BaseModel):
    enabled: bool = False
    provider: str = "deepseek"
    model: str = "deepseek-chat"
    api_key: str | None = None
    api_base: str | None = None


class LLMSettings(BaseModel):
    """LLM æ¨¡å‹é…ç½®"""
    provider: str = "openai"
    model: str = "gpt-4o-mini"
    api_key: str = ""
    api_base: str | None = None
    temperature: float = 0.3
    max_tokens: int = 2000
    timeout: int = 60
    max_retries: int = 2
    fallback: LLMFallbackSettings = Field(default_factory=LLMFallbackSettings)


class PromptSettings(BaseModel):
    role: str = ""
    capabilities: str = ""
    constraints: str = ""
    output_format: str = ""


class ToolSettings(BaseModel):
    max_iterations: int = 5
    parallel_calls: bool = False


class AgentSettings(BaseModel):
    """Agent æ ¸å¿ƒè¡Œä¸ºé…ç½®"""
    name: str = "feishu-case-assistant"
    prompt: PromptSettings = Field(default_factory=PromptSettings)
    tools: ToolSettings = Field(default_factory=ToolSettings)


class CleanupSettings(BaseModel):
    interval_seconds: int = 300
    enabled: bool = True


class SessionSettings(BaseModel):
    max_rounds: int = 5
    ttl_minutes: int = 30
    max_context_tokens: int = 4000
    cleanup: CleanupSettings = Field(default_factory=CleanupSettings)


class WebhookDedupSettings(BaseModel):
    enabled: bool = True
    ttl_seconds: int = 300
    max_size: int = 10000


class WebhookFilterSettings(BaseModel):
    allowed_message_types: list[str] = Field(default_factory=lambda: ["text"])
    private_chat_only: bool = True
    ignore_bot_message: bool = True


class WebhookSettings(BaseModel):
    path: str = "/feishu/webhook"
    dedup: WebhookDedupSettings = Field(default_factory=WebhookDedupSettings)
    filter: WebhookFilterSettings = Field(default_factory=WebhookFilterSettings)


class ReplyTemplateSettings(BaseModel):
    no_result: str = "æœªæ‰¾åˆ°ç›¸å…³è®°å½•ï¼Œè¯·å°è¯•è°ƒæ•´æŸ¥è¯¢æ¡ä»¶ã€‚"
    error: str = "æŠ±æ­‰ï¼Œå¤„ç†è¯·æ±‚æ—¶é‡åˆ°é—®é¢˜ï¼š{message}"
    timeout: str = "æ€è€ƒè¶…æ—¶ï¼Œè¯·ç®€åŒ–é—®é¢˜åé‡è¯•ã€‚"
    welcome: str = "ä½ å¥½ï¼æˆ‘æ˜¯æ¡ˆä»¶åŠ©æ‰‹ã€‚"
    guide: str = 'ç›®å‰ä»…æ”¯æŒæ¡ˆä»¶/æ–‡æ¡£æŸ¥è¯¢ï¼Œå¯è¯•è¯•ï¼š"æ‰¾ä¸€ä¸‹æå››çš„æ¡ˆå­" æˆ– "1æœˆ28å·æœ‰ä»€ä¹ˆåº­è¦å¼€"ã€‚'
    small_talk: str = "ä½ å¥½ï¼æˆ‘å¯ä»¥å¸®ä½ æŸ¥è¯¢æ¡ˆä»¶æˆ–æ–‡æ¡£ã€‚"
    thanks: str = "ä¸å®¢æ°”ï¼éœ€è¦æŸ¥è¯¢æ¡ˆä»¶æˆ–æ–‡æ¡£éšæ—¶å‘Šè¯‰æˆ‘ã€‚"
    goodbye: str = "å¥½çš„ï¼Œå¦‚éœ€æŸ¥è¯¢éšæ—¶æ‰¾æˆ‘ã€‚"


class ReplyCaseListSettings(BaseModel):
    title: str = "ğŸ“Œ æ¡ˆä»¶æŸ¥è¯¢ç»“æœï¼ˆå…± {count} æ¡ï¼‰"
    item: str = (
        "{index}ï¸âƒ£ {client} vs {opponent}ï½œ{cause}\n"
        "   â€¢ æ¡ˆå·ï¼š{case_number}\n"
        "   â€¢ æ³•é™¢ï¼š{court}\n"
        "   â€¢ ç¨‹åºï¼š{stage}\n"
        "   â€¢ ğŸ”— æŸ¥çœ‹è¯¦æƒ…ï¼š{record_url}"
    )


class ReplySettings(BaseModel):
    templates: ReplyTemplateSettings = Field(default_factory=ReplyTemplateSettings)
    case_list: ReplyCaseListSettings = Field(default_factory=ReplyCaseListSettings)


class LoggingFileSettings(BaseModel):
    enabled: bool = False
    path: str = "logs/feishu-agent.log"
    max_size_mb: int = 100
    backup_count: int = 5


class LoggingOutputSettings(BaseModel):
    console: bool = True
    file: LoggingFileSettings = Field(default_factory=LoggingFileSettings)


class LoggingMaskSettings(BaseModel):
    enabled: bool = True
    fields: list[str] = Field(default_factory=list)


class LoggingSettings(BaseModel):
    level: str = "INFO"
    format: str = "json"
    output: LoggingOutputSettings = Field(default_factory=LoggingOutputSettings)
    mask: LoggingMaskSettings = Field(default_factory=LoggingMaskSettings)


class RateLimitSettings(BaseModel):
    enabled: bool = True
    user_rpm: int = 30
    global_rpm: int = 300
    max_concurrency: int = 10


class HealthDependency(BaseModel):
    name: str
    url: str
    timeout: int = 5


class HealthSettings(BaseModel):
    path: str = "/health"
    check_dependencies: bool = True
    dependencies: list[HealthDependency] = Field(default_factory=list)


class Settings(BaseModel):
    """å…¨å±€é…ç½®èšåˆæ ¹"""
    server: ServerSettings = Field(default_factory=ServerSettings)
    feishu: FeishuSettings = Field(default_factory=FeishuSettings)
    mcp: MCPSettings = Field(default_factory=MCPSettings)
    postgres: PostgresSettings = Field(default_factory=PostgresSettings)
    llm: LLMSettings = Field(default_factory=LLMSettings)
    agent: AgentSettings = Field(default_factory=AgentSettings)
    session: SessionSettings = Field(default_factory=SessionSettings)
    webhook: WebhookSettings = Field(default_factory=WebhookSettings)
    reply: ReplySettings = Field(default_factory=ReplySettings)
    logging: LoggingSettings = Field(default_factory=LoggingSettings)
    rate_limit: RateLimitSettings = Field(default_factory=RateLimitSettings)
    health: HealthSettings = Field(default_factory=HealthSettings)
# endregion


# region é…ç½®åŠ è½½é€»è¾‘


def _expand_env(value: Any) -> Any:
    """é€’å½’å±•å¼€é…ç½®ä¸­çš„ç¯å¢ƒå˜é‡å ä½ç¬¦ (${VAR} æˆ– ${VAR:-default})"""
    if isinstance(value, str):
        def replace(match: re.Match[str]) -> str:
            expr = match.group(1)
            if ":-" in expr:
                key, default = expr.split(":-", 1)
                return os.getenv(key, default)
            return os.getenv(expr, "")

        return _ENV_PATTERN.sub(replace, value)
    if isinstance(value, list):
        return [_expand_env(item) for item in value]
    if isinstance(value, dict):
        return {key: _expand_env(val) for key, val in value.items()}
    return value


def _load_yaml(path: Path) -> dict[str, Any]:
    """è¯»å– YAML é…ç½®æ–‡ä»¶"""
    if not path.exists():
        return {}
    data = yaml.safe_load(path.read_text(encoding="utf-8")) or {}
    return _expand_env(data)


def _set_nested(data: dict[str, Any], keys: list[str], value: Any) -> None:
    current = data
    for key in keys[:-1]:
        current = current.setdefault(key, {})
    current[keys[-1]] = value


def _apply_env_overrides(data: dict[str, Any]) -> dict[str, Any]:
    """
    åº”ç”¨ç¯å¢ƒå˜é‡è¦†ç›–
    
    ä¼˜å…ˆçº§: æ˜¾å¼ç¯å¢ƒå˜é‡ > config.yaml > é»˜è®¤å€¼
    """
    mapping = {
        "LLM_PROVIDER": ["llm", "provider"],
        "LLM_MODEL": ["llm", "model"],
        "FEISHU_BOT_APP_ID": ["feishu", "app_id"],
        "FEISHU_BOT_APP_SECRET": ["feishu", "app_secret"],
        "FEISHU_BOT_VERIFICATION_TOKEN": ["feishu", "verification_token"],
        "FEISHU_BOT_ENCRYPT_KEY": ["feishu", "encrypt_key"],
        "MCP_SERVER_BASE": ["mcp", "base_url"],
        "POSTGRES_DSN": ["postgres", "dsn"],
        "POSTGRES_MIN_SIZE": ["postgres", "min_size"],
        "POSTGRES_MAX_SIZE": ["postgres", "max_size"],
        "POSTGRES_TIMEOUT": ["postgres", "timeout"],
        "LLM_API_KEY": ["llm", "api_key"],
        "LLM_API_BASE": ["llm", "api_base"],
        "LLM_FALLBACK_API_KEY": ["llm", "fallback", "api_key"],
    }
    for env_key, path in mapping.items():
        env_value = os.getenv(env_key)
        if env_value is not None and env_value != "":
            _set_nested(data, path, env_value)
    return data


def load_settings(config_path: str | None = None) -> Settings:
    """åŠ è½½å¹¶éªŒè¯å®Œæ•´é…ç½®"""
    path = Path(config_path or os.getenv("CONFIG_PATH", "config.yaml"))
    data = _load_yaml(path)
    data = _apply_env_overrides(data)
    return Settings.model_validate(data)


@lru_cache(maxsize=1)
def get_settings() -> Settings:
    """è·å–å•ä¾‹é…ç½®å¯¹è±¡ (LRU Cache)"""
    return load_settings()
# endregion
