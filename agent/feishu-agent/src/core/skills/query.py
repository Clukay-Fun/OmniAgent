"""
æè¿°: æ¡ˆä»¶æŸ¥è¯¢æŠ€èƒ½
ä¸»è¦åŠŸèƒ½:
    - å¤šç»´è¡¨æ ¼æ¡ˆä»¶æŸ¥è¯¢
    - é£ä¹¦æ–‡æ¡£å†…å®¹æœç´¢
    - æ ¼å¼åŒ–æŸ¥è¯¢ç»“æœå¹¶æ„å»ºæ¶ˆæ¯å¡ç‰‡
"""

from __future__ import annotations

import logging
import re
from typing import Any

from src.core.skills.base import BaseSkill
from src.core.types import SkillContext, SkillResult

logger = logging.getLogger(__name__)


# region æ¡ˆä»¶æŸ¥è¯¢æŠ€èƒ½
class QuerySkill(BaseSkill):
    """
    æ¡ˆä»¶æŸ¥è¯¢æŠ€èƒ½

    åŠŸèƒ½:
        - è¯†åˆ«æŸ¥è¯¢æ„å›¾ï¼ˆè¡¨æ ¼/æ–‡æ¡£ï¼‰
        - æå–å…³é”®è¯å’Œæ—¶é—´èŒƒå›´
        - è°ƒç”¨å¯¹åº” MCP å·¥å…·è·å–æ•°æ®
    """
    
    name: str = "QuerySkill"
    description: str = "æŸ¥è¯¢æ¡ˆä»¶ã€å¼€åº­ã€å½“äº‹äººç­‰ä¿¡æ¯"

    def __init__(
        self,
        mcp_client: Any,
        settings: Any = None,
        llm_client: Any = None,
        skills_config: dict[str, Any] | None = None,
    ) -> None:
        """
        åˆå§‹åŒ–æŸ¥è¯¢æŠ€èƒ½

        å‚æ•°:
            mcp_client: MCP å®¢æˆ·ç«¯å®ä¾‹
            settings: é…ç½®ä¿¡æ¯
        """
        self._mcp = mcp_client
        self._settings = settings
        self._llm = llm_client
        self._skills_config = skills_config or {}

        self._table_aliases = self._skills_config.get("table_aliases", {}) or {}
        self._alias_lookup = self._build_alias_lookup(self._table_aliases)
        self._table_recognition = self._skills_config.get("table_recognition", {}) or {}
        self._confidence_threshold = float(
            self._table_recognition.get("confidence_threshold", 0.65)
        )
        self._auto_confirm_threshold = float(
            self._table_recognition.get("auto_confirm_threshold", 0.85)
        )
        self._max_candidates = int(self._table_recognition.get("max_candidates", 3))

        # ç»“æœæ ¼å¼åŒ–å­—æ®µé…ç½®ï¼ˆæ”¯æŒè‡ªå®šä¹‰ï¼‰
        query_cfg = self._skills_config.get("query", {})
        if not query_cfg:
            query_cfg = self._skills_config.get("skills", {}).get("query", {})
        self._query_cfg = query_cfg
        self._display_fields = query_cfg.get("display_fields", {
            "title_left": "å§”æ‰˜äººåŠè”ç³»æ–¹å¼",
            "title_right": "å¯¹æ–¹å½“äº‹äºº",
            "title_suffix": "æ¡ˆç”±",
            "case_no": "æ¡ˆå·",
            "court": "å®¡ç†æ³•é™¢",
            "stage": "ç¨‹åºé˜¶æ®µ",
        })
        self._all_cases_keywords = query_cfg.get(
            "all_cases_keywords",
            [
                "æ‰€æœ‰æ¡ˆä»¶",
                "å…¨éƒ¨æ¡ˆä»¶",
                "æ¡ˆä»¶åˆ—è¡¨",
                "åˆ—å‡ºæ¡ˆä»¶",
                "æ‰€æœ‰é¡¹ç›®",
                "å…¨éƒ¨é¡¹ç›®",
                "æ‰€æœ‰æ¡ˆå­",
                "å…¨éƒ¨æ¡ˆå­",
                "æŸ¥å…¨éƒ¨",
            ],
        )
        self._keep_view_keywords = query_cfg.get(
            "keep_view_keywords",
            ["æŒ‰è§†å›¾", "å½“å‰è§†å›¾", "ä»…è§†å›¾", "è§†å›¾å†…", "åªçœ‹è§†å›¾"],
        )
        self._all_cases_ignore_default_view = bool(
            query_cfg.get("all_cases_ignore_default_view", True)
        )

    async def execute(self, context: SkillContext) -> SkillResult:
        """
        æ‰§è¡ŒæŸ¥è¯¢é€»è¾‘

        å‚æ•°:
            context: æŠ€èƒ½ä¸Šä¸‹æ–‡

        è¿”å›:
            æŸ¥è¯¢ç»“æœï¼ˆæ–‡æœ¬æˆ–å¡ç‰‡ï¼‰
        """
        query = context.query.strip()
        extra = context.extra or {}

        if self._is_refresh_command(query):
            return await self._refresh_tables()

        target = self._select_target(query)
        if target == "doc":
            params = self._build_doc_params(query)
            try:
                result = await self._mcp.call_tool("feishu.v1.doc.search", params)
                documents = result.get("documents", [])
                if not documents:
                    return self._empty_result("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")
                return self._format_doc_result(documents)
            except Exception as e:
                logger.error("QuerySkill execution error: %s", e)
                return SkillResult(
                    success=False,
                    skill_name=self.name,
                    message=str(e),
                    reply_text="æŸ¥è¯¢å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                )

        pending = self._get_pending_table(context)
        if pending:
            resolved = self._resolve_pending_response(query, pending)
            if resolved:
                query = pending.get("query") or query
                extra = dict(extra)
                extra["table_name"] = resolved["table_name"]
                extra["table_id"] = resolved.get("table_id")

        table_result = await self._resolve_table(query, extra)
        if table_result.get("status") == "need_confirm":
            return SkillResult(
                success=True,
                skill_name=self.name,
                data={"pending_table": table_result.get("pending_table")},
                message="éœ€è¦ç¡®è®¤è¡¨å",
                reply_text=table_result.get("reply_text", ""),
            )
        if table_result.get("status") != "resolved":
            return SkillResult(
                success=False,
                skill_name=self.name,
                message=table_result.get("message", "æ— æ³•è¯†åˆ«è¡¨"),
                reply_text=table_result.get("reply_text", "æ— æ³•è¯†åˆ«è¦æŸ¥è¯¢çš„è¡¨ï¼Œè¯·æ˜ç¡®è¡¨åã€‚"),
            )

        tool_name, params = self._build_bitable_params(query, extra, table_result)
        notice = table_result.get("notice")

        try:
            logger.info("Query tool selected: %s, params: %s", tool_name, params)
            result = await self._mcp.call_tool(tool_name, params)
            records = result.get("records", [])
            schema = result.get("schema")
            if not records:
                return self._empty_result("æœªæ‰¾åˆ°ç›¸å…³æ¡ˆä»¶è®°å½•")
            return self._format_case_result(records, notice=notice, schema=schema)
        except Exception as e:
            if tool_name == "feishu.v1.bitable.search_exact" and (
                "Field not found" in str(e) or "InvalidFilter" in str(e)
            ):
                try:
                    fallback_params: dict[str, Any] = {}
                    if params.get("table_id"):
                        fallback_params["table_id"] = params.get("table_id")
                    if params.get("view_id"):
                        fallback_params["view_id"] = params.get("view_id")
                    fallback_params["keyword"] = str(params.get("value") or "")
                    logger.warning(
                        "Exact field not found, fallback to keyword search: %s",
                        fallback_params,
                    )
                    result = await self._mcp.call_tool("feishu.v1.bitable.search_keyword", fallback_params)
                    records = result.get("records", [])
                    schema = result.get("schema")
                    if not records:
                        return self._empty_result("æœªæ‰¾åˆ°ç›¸å…³æ¡ˆä»¶è®°å½•")
                    return self._format_case_result(records, notice=notice, schema=schema)
                except Exception:
                    pass
            logger.error("QuerySkill execution error: %s", e)
            return SkillResult(
                success=False,
                skill_name=self.name,
                message=str(e),
                reply_text="æŸ¥è¯¢å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚",
            )

    def _select_target(self, query: str) -> str:
        """åˆ¤æ–­æŸ¥è¯¢ç±»å‹ï¼ˆè¡¨æ ¼/æ–‡æ¡£ï¼‰"""
        doc_keywords = ["æ–‡æ¡£", "èµ„æ–™", "æ–‡ä»¶", "åˆåŒ"]
        if any(kw in query for kw in doc_keywords):
            return "doc"
        return "bitable"

    def _build_doc_params(self, query: str) -> dict[str, Any]:
        params: dict[str, Any] = {}
        keyword = self._extract_keyword(query)
        if keyword:
            params["keyword"] = keyword
        return params

    def _build_alias_lookup(self, table_aliases: dict[str, Any]) -> dict[str, str]:
        lookup: dict[str, str] = {}
        for table_name, aliases in (table_aliases or {}).items():
            alias_list = [table_name]
            if isinstance(aliases, list):
                alias_list.extend([str(item) for item in aliases if item])
            for alias in alias_list:
                alias = str(alias).strip()
                if not alias:
                    continue
                lookup[alias] = table_name
        return lookup

    def _is_refresh_command(self, query: str) -> bool:
        cmd = query.strip().lower()
        return cmd in {"/refresh", "åˆ·æ–°", "åˆ·æ–°è¡¨ç»“æ„", "åˆ·æ–°è¡¨"}

    async def _refresh_tables(self) -> SkillResult:
        try:
            result = await self._mcp.call_tool(
                "feishu.v1.bitable.list_tables",
                {"refresh": True},
            )
            tables = result.get("tables", [])
            return SkillResult(
                success=True,
                skill_name=self.name,
                data={"tables": tables, "total": result.get("total", len(tables))},
                message="å·²åˆ·æ–°è¡¨ç»“æ„ç¼“å­˜",
                reply_text=f"å·²åˆ·æ–°è¡¨ç»“æ„ç¼“å­˜ï¼ˆ{len(tables)} å¼ è¡¨ï¼‰ã€‚",
            )
        except Exception as exc:
            logger.error("Refresh tables error: %s", exc)
            return SkillResult(
                success=False,
                skill_name=self.name,
                message=str(exc),
                reply_text="åˆ·æ–°è¡¨ç»“æ„å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚",
            )

    def _get_pending_table(self, context: SkillContext) -> dict[str, Any] | None:
        if context.last_skill != self.name:
            return None
        last_result = context.last_result or {}
        pending = last_result.get("pending_table")
        if isinstance(pending, dict):
            return pending
        return None

    def _resolve_pending_response(
        self,
        query: str,
        pending: dict[str, Any],
    ) -> dict[str, Any] | None:
        candidates = pending.get("candidates") or []
        if not isinstance(candidates, list):
            return None
        normalized = query.strip()
        confirm_words = {"æ˜¯", "ç¡®è®¤", "å¯¹", "å¥½çš„", "å¥½", "ok", "yes"}
        if normalized in confirm_words and len(candidates) == 1:
            return candidates[0]
        for candidate in candidates:
            name = candidate.get("table_name")
            if name and name == normalized:
                return candidate
        return None

    async def _resolve_table(self, query: str, extra: dict[str, Any]) -> dict[str, Any]:
        try:
            tables_result = await self._mcp.call_tool("feishu.v1.bitable.list_tables", {})
        except Exception as exc:
            logger.error("List tables failed: %s", exc)
            return {"status": "error", "message": str(exc)}

        tables = tables_result.get("tables", [])
        if not tables:
            return {
                "status": "error",
                "message": "æœªé…ç½®å¤šç»´è¡¨æ ¼",
                "reply_text": "å½“å‰æœªé…ç½®å¤šç»´è¡¨æ ¼ï¼Œæ— æ³•æŸ¥è¯¢ã€‚",
            }

        table_lookup = {item["table_name"]: item.get("table_id") for item in tables}
        table_names = list(table_lookup.keys())

        alias_match = self._match_alias(query)
        if alias_match and alias_match in table_lookup:
            logger.info("Table resolved by alias", extra={"table": alias_match, "method": "alias"})
            return {
                "status": "resolved",
                "table_name": alias_match,
                "table_id": table_lookup.get(alias_match),
                "confidence": 1.0,
                "method": "alias",
            }

        direct_match = self._match_table_name(query, table_names)
        if direct_match:
            logger.info("Table resolved by name", extra={"table": direct_match, "method": "direct"})
            return {
                "status": "resolved",
                "table_name": direct_match,
                "table_id": table_lookup.get(direct_match),
                "confidence": 1.0,
                "method": "direct",
            }

        llm_result = await self._llm_pick_table(query, table_names)
        candidates = self._normalize_candidates(llm_result.get("candidates"), table_names)
        if llm_result.get("table_name"):
            candidates = [llm_result["table_name"]] + [c for c in candidates if c != llm_result["table_name"]]
        candidates = candidates[: self._max_candidates]

        confidence = float(llm_result.get("confidence") or 0)
        selected = llm_result.get("table_name")
        if selected and selected not in table_lookup:
            selected = None

        logger.info(
            "Table resolved by llm",
            extra={
                "table": selected,
                "confidence": confidence,
                "candidates": candidates,
            },
        )

        if selected and confidence >= self._auto_confirm_threshold:
            return {
                "status": "resolved",
                "table_name": selected,
                "table_id": table_lookup.get(selected),
                "confidence": confidence,
                "method": "llm_high",
            }
        if selected and confidence >= self._confidence_threshold:
            return {
                "status": "resolved",
                "table_name": selected,
                "table_id": table_lookup.get(selected),
                "confidence": confidence,
                "method": "llm_medium",
                "notice": f"å·²ä¸ºæ‚¨å®šä½åˆ° {selected} è¡¨ã€‚",
            }

        reply_text = self._build_confirmation_reply(candidates, table_names)
        pending_table = {
            "query": query,
            "candidates": [
                {"table_name": name, "table_id": table_lookup.get(name)} for name in candidates
            ],
        }
        return {
            "status": "need_confirm",
            "reply_text": reply_text,
            "pending_table": pending_table,
        }

    def _match_alias(self, query: str) -> str | None:
        logger.info(f"Matching alias for query: '{query}', alias_lookup: {self._alias_lookup}")
        query_lower = query.lower()
        matched = []
        for alias, table in self._alias_lookup.items():
            if alias in query or alias.lower() in query_lower:
                matched.append((len(alias), table))
                logger.info(f"Matched alias: '{alias}' -> '{table}'")
        if not matched:
            logger.warning("No alias matched")
            return None
        matched.sort(reverse=True)
        result = matched[0][1]
        logger.info(f"Selected table: '{result}'")
        return result

    def _match_table_name(self, query: str, table_names: list[str]) -> str | None:
        matched = [name for name in table_names if name and name in query]
        if not matched:
            return None
        matched.sort(key=len, reverse=True)
        return matched[0]

    async def _llm_pick_table(self, query: str, table_names: list[str]) -> dict[str, Any]:
        if not self._llm or not table_names:
            return {}
        system = "ä½ æ˜¯è¡¨åè¯†åˆ«åŠ©æ‰‹ã€‚"
        prompt = (
            "è¯·æ ¹æ®ç”¨æˆ·é—®é¢˜ä»è¡¨ååˆ—è¡¨ä¸­é€‰æ‹©æœ€å¯èƒ½çš„è¡¨ï¼Œå¹¶è¿”å› JSONï¼š"
            "{\"table_name\": \"...\", \"confidence\": 0.0-1.0, \"reason\": \"...\", "
            "\"candidates\": [\"...\", \"...\"]}ã€‚åªè¿”å› JSONã€‚\n\n"
            f"è¡¨ååˆ—è¡¨ï¼š{', '.join(table_names)}\n"
            f"ç”¨æˆ·é—®é¢˜ï¼š{query}"
        )
        try:
            return await self._llm.chat_json(prompt, system=system)
        except Exception as exc:
            logger.warning("LLM table match failed: %s", exc)
            return {}

    def _normalize_candidates(self, candidates: Any, table_names: list[str]) -> list[str]:
        result: list[str] = []
        if isinstance(candidates, list):
            for item in candidates:
                if isinstance(item, str) and item in table_names:
                    result.append(item)
        return result

    def _build_confirmation_reply(self, candidates: list[str], all_tables: list[str]) -> str:
        templates = (self._table_recognition.get("templates") or {})
        single_tpl = templates.get("single_candidate", "è¯·ç¡®è®¤è¡¨åï¼š{table_name}")
        multi_tpl = templates.get("multi_candidate", "è¯·ç¡®è®¤è¡¨åï¼š\n{candidate_list}")
        no_match_tpl = templates.get("no_match", "å¯ç”¨è¡¨ï¼š{all_tables}")

        if len(candidates) == 1:
            return single_tpl.format(table_name=candidates[0])
        if 1 < len(candidates) <= self._max_candidates:
            candidate_list = "\n".join([f"- {name}" for name in candidates])
            return multi_tpl.format(candidate_list=candidate_list)
        return no_match_tpl.format(all_tables="ã€".join(all_tables))

    def _build_bitable_params(
        self,
        query: str,
        extra: dict[str, Any],
        table_result: dict[str, Any],
    ) -> tuple[str, dict[str, Any]]:
        params: dict[str, Any] = {}
        table_id = table_result.get("table_id")
        if table_id:
            params["table_id"] = table_id

        if self._is_all_cases_query(query):
            if self._all_cases_ignore_default_view and not self._should_keep_view_filter(query):
                params["ignore_default_view"] = True
            logger.info("Query scenario: all_cases")
            return "feishu.v1.bitable.search", params

        # ä¼˜å…ˆçº§1: æ£€æŸ¥æ˜¯å¦ä¸º"æˆ‘çš„æ¡ˆä»¶"æŸ¥è¯¢
        user_profile = extra.get("user_profile")
        if user_profile and user_profile.open_id and ("æˆ‘çš„" in query or "è‡ªå·±çš„" in query):
            # ä½¿ç”¨äººå‘˜å­—æ®µæœç´¢å·¥å…·ï¼Œé€šè¿‡ open_id ç²¾ç¡®åŒ¹é…ä¸»åŠå¾‹å¸ˆ
            logger.info(f"Query 'my cases' for user: {user_profile.name} (open_id: {user_profile.open_id})")
            params.update({
                "field": "ä¸»åŠå¾‹å¸ˆ",
                "open_id": user_profile.open_id,
            })
            logger.info("Query scenario: my_cases")
            return "feishu.v1.bitable.search_person", params

        # ä¼˜å…ˆçº§2: æ£€æŸ¥æ˜¯å¦æŒ‡å®šäº†å¾‹å¸ˆï¼ˆä¾‹å¦‚ï¼š"æŸ¥è¯¢å¼ ä¸‰çš„æ¡ˆä»¶"ã€"å¾‹å¸ˆæå››çš„æ¡ˆä»¶"ï¼‰
        # æ³¨æ„ï¼šç”±äºåªæœ‰å§“åï¼Œæ— æ³•è·å– open_idï¼Œä½¿ç”¨å…³é”®è¯æœç´¢
        import re
        lawyer_pattern = re.compile(r"(?:æŸ¥è¯¢|å¾‹å¸ˆ)?([^çš„\s]+)(?:çš„æ¡ˆä»¶|æ¡ˆä»¶)")
        match = lawyer_pattern.search(query)
        if match:
            lawyer_name = match.group(1).strip()
            # æ’é™¤ä¸€äº›å¸¸è§çš„éå¾‹å¸ˆå…³é”®è¯
            if lawyer_name not in ["æ‰€æœ‰", "å…¨éƒ¨", "ä»Šå¤©", "æ˜å¤©", "æœ¬å‘¨", "æœ¬æœˆ", "æˆ‘", "è‡ªå·±"]:
                # ä½¿ç”¨å…³é”®è¯æœç´¢
                logger.info(f"Query cases for lawyer: {lawyer_name}")
                params["keyword"] = lawyer_name
                logger.info("Query scenario: person_cases")
                return "feishu.v1.bitable.search_keyword", params

        date_from = extra.get("date_from")
        date_to = extra.get("date_to")
        if date_from or date_to:
            params.update({
                "field": self._guess_date_field(query),
                "date_from": date_from,
                "date_to": date_to,
            })
            return "feishu.v1.bitable.search_date_range", params

        exact_field = self._extract_exact_field(query)
        if exact_field:
            params.update(exact_field)
            logger.info("Query scenario: exact_match")
            return "feishu.v1.bitable.search_exact", params

        keyword = self._extract_keyword(query)
        if keyword:
            params["keyword"] = keyword
            logger.info("Query scenario: keyword")
            return "feishu.v1.bitable.search_keyword", params

        if self._all_cases_ignore_default_view and not self._should_keep_view_filter(query):
            params["ignore_default_view"] = True
        logger.info("Query scenario: full_scan")
        return "feishu.v1.bitable.search", params

    def _is_all_cases_query(self, query: str) -> bool:
        normalized = query.replace(" ", "")
        if any(token in normalized for token in self._all_cases_keywords):
            return True
        if ("æ‰€æœ‰" in normalized or "å…¨éƒ¨" in normalized) and ("æ¡ˆä»¶" in normalized or "é¡¹ç›®" in normalized):
            return True
        return False

    def _should_keep_view_filter(self, query: str) -> bool:
        normalized = query.replace(" ", "")
        return any(token in normalized for token in self._keep_view_keywords)

    def _guess_date_field(self, query: str) -> str:
        if "å¼€åº­" in query or "åº­å®¡" in query:
            return "å¼€åº­æ—¥"
        if "æˆªæ­¢" in query:
            return "æˆªæ­¢æ—¥"
        return "å¼€åº­æ—¥"

    def _extract_exact_field(self, query: str) -> dict[str, str] | None:
        exact_patterns: list[tuple[str, str]] = [
            (r"(?:æ¡ˆå·|æ¡ˆä»¶å·)[æ˜¯ä¸º:ï¼š\s]*([A-Za-z0-9\-_/ï¼ˆï¼‰()_\u4e00-\u9fa5]+)", "æ¡ˆå·"),
            (r"(?:é¡¹ç›®ID|é¡¹ç›®Id|é¡¹ç›®id|é¡¹ç›®ç¼–å·|é¡¹ç›®å·)[æ˜¯ä¸º:ï¼š\s]*([A-Za-z0-9\-_/ï¼ˆï¼‰()_\u4e00-\u9fa5]+)", "é¡¹ç›®ID"),
            (r"(?:ç¼–å·)[æ˜¯ä¸º:ï¼š\s]*([A-Za-z0-9\-_/ï¼ˆï¼‰()_\u4e00-\u9fa5]+)", "æ¡ˆå·"),
        ]
        for pattern, field in exact_patterns:
            match = re.search(pattern, query)
            if not match:
                continue
            value = match.group(1).strip()
            if value:
                return {"field": field, "value": value}
        return None

    def _extract_keyword(self, query: str) -> str:
        """
        æå–å…³é”®è¯

        é€»è¾‘:
            - å»é™¤å¸¸è§æ— æ•ˆè¯ï¼ˆå¦‚åŠ¨ä½œè¯ã€é€šç”¨è¯ï¼‰
            - å¦‚æœè¿‡æ»¤åæ— æœ‰æ•ˆå…³é”®è¯ï¼Œè¿”å›ç©ºï¼ˆæŸ¥è¯¢å…¨éƒ¨ï¼‰

        å‚æ•°:
            query: åŸå§‹æŸ¥è¯¢æ–‡æœ¬
        è¿”å›:
            å¤„ç†åçš„å…³é”®è¯
        """
        keyword = query
        
        # æŸ¥è¯¢åŠ¨ä½œè¯ï¼ˆéœ€è¦å»é™¤ï¼‰
        action_words = [
            "æ‰¾ä¸€ä¸‹", "æŸ¥ä¸€ä¸‹", "æŸ¥è¯¢", "æœç´¢", "å¸®æˆ‘", "è¯·å¸®æˆ‘", 
            "ä¸€ä¸‹", "ä½ èƒ½", "èƒ½ä¸èƒ½", "å¯ä»¥", "è¯·",
        ]
        
        # é€šç”¨è¯­ä¹‰è¯ï¼ˆéœ€è¦å»é™¤ï¼Œä½†ä¸æ˜¯å…³é”®è¯ï¼‰
        general_words = [
            "æ¡ˆå­", "æ¡ˆä»¶", "æœ‰ä»€ä¹ˆ", "æœ‰å“ªäº›", "éƒ½æœ‰å“ªäº›", "ç›®å‰",
            "åº­è¦å¼€", "åº­å®¡", "ä¿¡æ¯", "è¯¦æƒ…", "çš„", "å—", "å‘¢",
            "çœ‹çœ‹", "å‘Šè¯‰æˆ‘", "åˆ—å‡º", "å¾‹å¸ˆ", "æ³•å®˜", "å½“äº‹äºº",
            "å§”æ‰˜äºº", "è¢«å‘Š", "åŸå‘Š", "å¼€åº­", "æ¡ˆ",
            "æ‰€æœ‰", "å…¨éƒ¨", "åˆ—è¡¨", "å…¨éƒ¨æ¡ˆä»¶", "æ‰€æœ‰æ¡ˆä»¶", "å…¨éƒ¨é¡¹ç›®", "æ‰€æœ‰é¡¹ç›®",
        ]
        
        for word in action_words + general_words:
            keyword = keyword.replace(word, "")
        
        keyword = keyword.strip()
        
        # å¦‚æœå…³é”®è¯å¤ªçŸ­æˆ–åªæ˜¯å¸¸è§è¯ï¼Œè¿”å›ç©ºï¼ˆæŸ¥è¯¢å…¨éƒ¨ï¼‰
        if len(keyword) <= 1:
            return ""
            
        return keyword

    def _empty_result(self, message: str) -> SkillResult:
        """æ„é€ ç©ºç»“æœå“åº”"""
        return SkillResult(
            success=True,
            skill_name=self.name,
            data={"records": [], "total": 0},
            message=message,
            reply_text=f"{message}ï¼Œè¯·å°è¯•è°ƒæ•´æŸ¥è¯¢æ¡ä»¶ã€‚",
        )

    def _format_case_result(
        self,
        records: list[dict[str, Any]],
        notice: str | None = None,
        schema: list[dict[str, Any]] | None = None,
    ) -> SkillResult:
        """æ ¼å¼åŒ–æ¡ˆä»¶æŸ¥è¯¢ç»“æœ"""
        count = len(records)
        title = f"ğŸ“Œ æ¡ˆä»¶æŸ¥è¯¢ç»“æœï¼ˆå…± {count} æ¡ï¼‰"
        
        items = []
        df = self._display_fields  # ä½¿ç”¨é…ç½®çš„å­—æ®µå
        for i, record in enumerate(records, start=1):
            fields = record.get("fields_text") or record.get("fields", {})
            item = (
                f"{i}ï¸âƒ£ {fields.get(df.get('title_left', ''), '')} vs {fields.get(df.get('title_right', ''), '')}ï½œ{fields.get(df.get('title_suffix', ''), '')}\n"
                f"   â€¢ æ¡ˆå·ï¼š{fields.get(df.get('case_no', 'æ¡ˆå·'), '')}\n"
                f"   â€¢ æ³•é™¢ï¼š{fields.get(df.get('court', 'å®¡ç†æ³•é™¢'), '')}\n"
                f"   â€¢ ç¨‹åºï¼š{fields.get(df.get('stage', 'ç¨‹åºé˜¶æ®µ'), '')}\n"
                f"   â€¢ ğŸ”— æŸ¥çœ‹è¯¦æƒ…ï¼š{record.get('record_url', '')}"
            )
            items.append(item)
        
        parts = [title]
        if notice:
            parts = [notice, "", title]
        reply_text = "\n\n".join(parts + items)
        
        # æ„å»ºå¡ç‰‡
        card = self._build_card(title, items, notice=notice)
        
        return SkillResult(
            success=True,
            skill_name=self.name,
            data={"records": records, "total": count, "schema": schema or []},
            message=f"æŸ¥è¯¢åˆ° {count} æ¡è®°å½•",
            reply_type="card",
            reply_text=reply_text,
            reply_card=card,
        )

    def _format_doc_result(self, documents: list[dict[str, Any]]) -> SkillResult:
        """æ ¼å¼åŒ–æ–‡æ¡£æŸ¥è¯¢ç»“æœ"""
        count = len(documents)
        title = f"ğŸ“„ æ–‡æ¡£æœç´¢ç»“æœï¼ˆå…± {count} æ¡ï¼‰"
        
        items = []
        for i, doc in enumerate(documents, start=1):
            item = (
                f"{i}. {doc.get('title', 'æœªå‘½åæ–‡æ¡£')}\n"
                f"   {doc.get('preview', '')}\n"
                f"   ğŸ”— {doc.get('url', '')}"
            )
            items.append(item)
        
        reply_text = "\n\n".join([title] + items)
        
        return SkillResult(
            success=True,
            skill_name=self.name,
            data={"documents": documents, "total": count},
            message=f"æœç´¢åˆ° {count} ç¯‡æ–‡æ¡£",
            reply_type="text",
            reply_text=reply_text,
        )

    def _build_card(self, title: str, items: list[str], notice: str | None = None) -> dict[str, Any]:
        """æ„å»ºé£ä¹¦æ¶ˆæ¯å¡ç‰‡"""
        elements = []
        if notice:
            elements.append({"tag": "markdown", "content": notice})
        elements.extend({"tag": "markdown", "content": item} for item in items)
        return {
            "config": {"wide_screen_mode": True},
            "header": {
                "title": {"tag": "plain_text", "content": title},
            },
            "elements": elements,
        }
# endregion
